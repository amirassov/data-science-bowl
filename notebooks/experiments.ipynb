{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def dice_loss(input, target):\n",
    "    EPS = 1e-15\n",
    "    dice_target = (target == 1).float()\n",
    "    dice_input = input\n",
    "    \n",
    "    intersection = (dice_target * dice_input).sum() + EPS\n",
    "    union = dice_target.sum() + dice_input.sum() + EPS\n",
    "    return 2.0 * intersection / union\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        return dice_loss(input, target)\n",
    "\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, size_average=True):\n",
    "        super().__init__()\n",
    "        self.size_average = size_average\n",
    "        self.dice = DiceLoss()\n",
    "        self.bce = nn.modules.loss.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return 0.5 * self.bce(input, target) - self.dice(input, target)\n",
    "\n",
    "\n",
    "class BCEDiceLossMulti(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.bce_dice = BCEDiceLoss()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = 0\n",
    "        for cls in range(self.num_classes):\n",
    "            loss += self.bce_dice(input[:, cls], target[:, cls])\n",
    "        return loss / self.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def dice_loss(preds, trues, is_average=True):\n",
    "    num = preds.size(0)\n",
    "    preds = preds.view(num, -1)\n",
    "    trues = trues.view(num, -1)\n",
    "    intersection = (preds * trues).sum(1)\n",
    "    scores = 2.0 * (intersection + 1) / (preds.sum(1) + trues.sum(1) + 1)\n",
    "\n",
    "    if is_average:\n",
    "        score = scores.sum() / num\n",
    "        return torch.clamp(score, 0., 1.)\n",
    "    else:\n",
    "        return scores\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, size_average=True):\n",
    "        super().__init__()\n",
    "        self.size_average = size_average\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        return dice_loss(F.sigmoid(input), target, is_average=self.size_average)\n",
    "\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, size_average=True):\n",
    "        super().__init__()\n",
    "        self.size_average = size_average\n",
    "        self.dice = DiceLoss(size_average=size_average)\n",
    "        self.bce = nn.modules.loss.BCEWithLogitsLoss(size_average=self.size_average)\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        return 0.5 * self.bce(input, target) - self.dice(input, target)\n",
    "\n",
    "\n",
    "class BCEDiceLossMulti(nn.Module):\n",
    "    def __init__(self, size_average=True, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.size_average = size_average\n",
    "        self.bce_dice = BCEDiceLoss(size_average=size_average)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = 0\n",
    "        for cls in range(self.num_classes):\n",
    "            loss += self.bce_dice(input[:, cls].contiguous(), target[:, cls].contiguous())\n",
    "        return loss / self.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b10f278>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhkFSYxgkNf8HyGqy7e2a2xUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107aebcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt_mask = cv2.imread(\"../../dsbowl_old/data/stage1_train/00071198d059ba7f5914a526d124d28e6d010c92466da21d4a04cd5413362552/masks/07a9bf1d7594af2763c86e93f05d22c4d5181353c6d3ab30a345b908ffe5aadc.png\")\n",
    "plt.imshow(gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../dstorch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dstorch import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.4836\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = utils.to_float_tensor(gt_mask / 255).view(1, 3, 256, 256)\n",
    "input =  torch.FloatTensor(1, 3, 256, 256).uniform_(0, 1)\n",
    "BCEDiceLossMulti(num_classes=3).forward(utils.variable(input), utils.variable(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.4839\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = utils.to_float_tensor(gt_mask[..., 0] / 255).view(1, 1, 256, 256)\n",
    "input =  torch.FloatTensor(1, 1, 256, 256).uniform_(0, 1)\n",
    "BCEDiceLoss().forward(utils.variable(input), utils.variable(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 , 0 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       â‹±       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "[torch.FloatTensor of size 1x1x256x256]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
